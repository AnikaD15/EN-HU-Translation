{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "milestone2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/AnikaD15/EN-HU-Translation/blob/main/milestone3.ipynb",
      "authorship_tag": "ABX9TyNEkNyPHWPHsoLAVPCg0WcJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnikaD15/EN-HU-Translation/blob/main/milestone3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGMBEXTfhJFd"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emOrdz_9hvkr"
      },
      "source": [
        "## Config \n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "base_path = \"/content/drive/MyDrive/DeepLearning/\"\n",
        "data_path1 = base_path + \"hun1.txt\"\n",
        "data_path2 = base_path + \"hun2.tsv\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_VN1BTmPytY"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUPMHdkTP1HY"
      },
      "source": [
        "def getLines(data_path):\n",
        "  with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "    new_lines = list()\n",
        "\n",
        "    # initializing punctuations string\n",
        "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "\n",
        "    # Removing punctuations in string\n",
        "    # Using loop + punctuation string\n",
        "    for line in lines:\n",
        "      for ele in line:\n",
        "          if ele in punc:\n",
        "              line = line.replace(ele, \"\")\n",
        "      new_lines.append(line)\n",
        "\n",
        "  return new_lines"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-Zu7rYNQJcG"
      },
      "source": [
        "def getTextAndChars(lines):\n",
        "  input_texts = []\n",
        "  target_texts = []\n",
        "  input_characters = set()\n",
        "  target_characters = set()\n",
        "\n",
        "  for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    # input_text, target_text, _ = line.split(\"\\t\")\n",
        "    target_text, input_text, _ = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "  input_characters = sorted(list(input_characters))\n",
        "  target_characters = sorted(list(target_characters)) \n",
        "\n",
        "  return input_texts, target_texts, input_characters, target_characters \n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH53RsOOQ63h"
      },
      "source": [
        "def numTokens(charSet):\n",
        "  return len(charSet)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoGsWg2nRdHC"
      },
      "source": [
        "def maxSeqLength(text):\n",
        "  return max([len(txt) for txt in text])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-D9-S42R1hy"
      },
      "source": [
        "def makeTokenIndex(charSet):\n",
        "  return dict([(char, i) for i, char in enumerate(charSet)])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqIG0zwoSOss"
      },
      "source": [
        "def setInputAndTargetData(input_text, target_text, input_token_index, target_token_index):\n",
        "  encoder_input_data = np.zeros(\n",
        "      (len(input_text), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        "  )\n",
        "  decoder_input_data = np.zeros(\n",
        "      (len(input_text), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        "  )\n",
        "  decoder_target_data = np.zeros(\n",
        "      (len(input_text), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        "  )\n",
        "\n",
        "  \n",
        "  for i, (input_text, target_text) in enumerate(zip(input_text, target_text)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "  return encoder_input_data, decoder_input_data, decoder_target_data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7O7HqEwj7LM"
      },
      "source": [
        "# Define an input sequence and process it.\n",
        "def getInputsAndOutputs(num_encoder_tokens, num_decoder_tokens, latent_dim=latent_dim):\n",
        "  encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
        "  encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
        "  encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "  # We discard `encoder_outputs` and only keep the states.\n",
        "  encoder_states = [state_h, state_c]\n",
        "\n",
        "  # Set up the decoder, using `encoder_states` as initial state.\n",
        "  decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "  # We set up our decoder to return full output sequences,\n",
        "  # and to return internal states as well. We don't use the\n",
        "  # return states in the training model, but we will use them in inference.\n",
        "  decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "  decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "  decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "  return encoder_inputs, decoder_inputs, decoder_outputs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSZq_5zkYFX-"
      },
      "source": [
        "def splitData(data, valid_split, test_split):\n",
        "  # array index boundary\n",
        "  v_point = int(len(data)*(1-valid_split-test_split))\n",
        "  t_point = int(len(data)*(1-test_split))\n",
        "\n",
        "  data_train = data[:t_point]\n",
        "  data_valid = data[v_point:t_point]\n",
        "  data_test = data[t_point:]\n",
        "\n",
        "  return data_train, data_valid, data_test"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB8RhX0HpdV0"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "        \n",
        "    return decoded_sentence"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def duplicates(lst, item):\n",
        "  return [i for i, x in enumerate(lst) if x == item]"
      ],
      "metadata": {
        "id": "yx_O0Zly_Hl-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn_4qmSN_asO"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv2Zkpyxh5J9",
        "outputId": "b53e00f7-7a65-4849-c1fa-a3e1fcc0e225"
      },
      "source": [
        "# Vectorize the data.\n",
        "lines1 = getLines(data_path1)\n",
        "lines2 = getLines(data_path2)\n",
        "\n",
        "lines = lines1+lines2\n",
        "\n",
        "input_text, target_text, input_characters, target_characters = getTextAndChars(lines)\n",
        "\n",
        "num_encoder_tokens = numTokens(input_characters)\n",
        "num_decoder_tokens = numTokens(target_characters)\n",
        "max_encoder_seq_length = maxSeqLength(input_text)\n",
        "max_decoder_seq_length = maxSeqLength(target_text)\n",
        "\n",
        "print(\"Number of samples:\", len(input_text))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "# character's lexographical order\n",
        "input_token_index = makeTokenIndex(input_characters) \n",
        "target_token_index = makeTokenIndex(target_characters)\n",
        "\n",
        "# encoder_input_data, decoder_input_data, decoder_target_data = setInputAndTargetData(input_text, target_text, input_token_index, target_token_index)\n",
        "                                                                                    \n",
        "encoder_inputs, decoder_inputs, decoder_outputs = getInputsAndOutputs(num_encoder_tokens, num_decoder_tokens)                                                                          \n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 81\n",
            "Number of unique output tokens: 72\n",
            "Max sequence length for inputs: 54\n",
            "Max sequence length for outputs: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Data"
      ],
      "metadata": {
        "id": "upoHKugRTHyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training, validation, test data\n",
        "valid_split = 0.2\n",
        "test_split  = 0.1\n",
        "\n",
        "input_text_train, input_text_valid, input_text_test = splitData(input_text, valid_split, test_split)\n",
        "target_text_train, target_text_valid, target_text_test = splitData(target_text, valid_split, test_split)"
      ],
      "metadata": {
        "id": "qohTgHGjTRx9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfYXsKzGFqt9"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SfoIpUYkyDn"
      },
      "source": [
        "# Define the model that will turn \n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQdAqvrYGhBu"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2_L2KVYI6kJ"
      },
      "source": [
        "# training, validation, test encoder/decoder data\n",
        "encoder_input_data_train, decoder_input_data_train, decoder_target_data_train = setInputAndTargetData(input_text_train, target_text_train, input_token_index, target_token_index)\n",
        "encoder_input_data_valid, decoder_input_data_valid, decoder_target_data_valid = setInputAndTargetData(input_text_valid, target_text_valid, input_token_index, target_token_index)\n",
        "encoder_input_data_test, decoder_input_data_test, decoder_target_data_test = setInputAndTargetData(input_text_test, target_text_test, input_token_index, target_token_index)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J99m4f7TpAeX"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaFvxKaAHrRP"
      },
      "source": [
        "es = EarlyStopping(monitor='val_accuracy', \n",
        "                   patience=20, verbose=1,\n",
        "                   restore_best_weights=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi13jaVCH5Dq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6d5516-ddfa-47b9-cb57-95d7df2cb9f6"
      },
      "source": [
        "model.fit(\n",
        "    [encoder_input_data_train, decoder_input_data_train],\n",
        "    decoder_target_data_train,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[es],\n",
        "    epochs=epochs,\n",
        "    validation_data = ([encoder_input_data_valid, decoder_input_data_valid],\n",
        "    decoder_target_data_valid)\n",
        ")\n",
        "# Save model\n",
        "model.save(base_path + \"model\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "141/141 [==============================] - 13s 41ms/step - loss: 2.4193 - accuracy: 0.3588 - val_loss: 2.5268 - val_accuracy: 0.3121\n",
            "Epoch 2/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 1.8510 - accuracy: 0.4916 - val_loss: 2.0185 - val_accuracy: 0.4132\n",
            "Epoch 3/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 1.5789 - accuracy: 0.5423 - val_loss: 1.7571 - val_accuracy: 0.4871\n",
            "Epoch 4/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 1.4538 - accuracy: 0.5745 - val_loss: 1.6585 - val_accuracy: 0.5099\n",
            "Epoch 5/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 1.3595 - accuracy: 0.6013 - val_loss: 1.5661 - val_accuracy: 0.5299\n",
            "Epoch 6/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 1.2881 - accuracy: 0.6206 - val_loss: 1.5480 - val_accuracy: 0.5391\n",
            "Epoch 7/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 1.2266 - accuracy: 0.6371 - val_loss: 1.4434 - val_accuracy: 0.5669\n",
            "Epoch 8/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 1.1740 - accuracy: 0.6524 - val_loss: 1.3687 - val_accuracy: 0.5838\n",
            "Epoch 9/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 1.1446 - accuracy: 0.6601 - val_loss: 1.3259 - val_accuracy: 0.5973\n",
            "Epoch 10/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 1.1383 - accuracy: 0.6628 - val_loss: 1.2870 - val_accuracy: 0.6095\n",
            "Epoch 11/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 1.1025 - accuracy: 0.6712 - val_loss: 1.2482 - val_accuracy: 0.6194\n",
            "Epoch 12/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 1.0432 - accuracy: 0.6868 - val_loss: 1.1741 - val_accuracy: 0.6469\n",
            "Epoch 13/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 1.0094 - accuracy: 0.6963 - val_loss: 1.1501 - val_accuracy: 0.6524\n",
            "Epoch 14/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.9812 - accuracy: 0.7041 - val_loss: 1.1255 - val_accuracy: 0.6580\n",
            "Epoch 15/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.9463 - accuracy: 0.7132 - val_loss: 1.0628 - val_accuracy: 0.6763\n",
            "Epoch 16/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.9130 - accuracy: 0.7236 - val_loss: 1.0291 - val_accuracy: 0.6897\n",
            "Epoch 17/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.8837 - accuracy: 0.7323 - val_loss: 1.0028 - val_accuracy: 0.6932\n",
            "Epoch 18/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.8567 - accuracy: 0.7400 - val_loss: 1.0020 - val_accuracy: 0.6898\n",
            "Epoch 19/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.8297 - accuracy: 0.7486 - val_loss: 0.9378 - val_accuracy: 0.7156\n",
            "Epoch 20/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.8045 - accuracy: 0.7553 - val_loss: 0.8878 - val_accuracy: 0.7332\n",
            "Epoch 21/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.7806 - accuracy: 0.7624 - val_loss: 0.8715 - val_accuracy: 0.7348\n",
            "Epoch 22/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.7578 - accuracy: 0.7691 - val_loss: 0.8404 - val_accuracy: 0.7421\n",
            "Epoch 23/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.7345 - accuracy: 0.7758 - val_loss: 0.7992 - val_accuracy: 0.7606\n",
            "Epoch 24/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.7117 - accuracy: 0.7831 - val_loss: 0.7909 - val_accuracy: 0.7622\n",
            "Epoch 25/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.6913 - accuracy: 0.7891 - val_loss: 0.7560 - val_accuracy: 0.7714\n",
            "Epoch 26/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.6710 - accuracy: 0.7959 - val_loss: 0.7297 - val_accuracy: 0.7792\n",
            "Epoch 27/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.6527 - accuracy: 0.8013 - val_loss: 0.7175 - val_accuracy: 0.7840\n",
            "Epoch 28/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.6349 - accuracy: 0.8067 - val_loss: 0.6923 - val_accuracy: 0.7905\n",
            "Epoch 29/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.6175 - accuracy: 0.8117 - val_loss: 0.6676 - val_accuracy: 0.7999\n",
            "Epoch 30/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.6003 - accuracy: 0.8169 - val_loss: 0.6474 - val_accuracy: 0.8042\n",
            "Epoch 31/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.5841 - accuracy: 0.8211 - val_loss: 0.6276 - val_accuracy: 0.8117\n",
            "Epoch 32/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.5699 - accuracy: 0.8263 - val_loss: 0.6071 - val_accuracy: 0.8193\n",
            "Epoch 33/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.5543 - accuracy: 0.8306 - val_loss: 0.5915 - val_accuracy: 0.8257\n",
            "Epoch 34/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.5391 - accuracy: 0.8351 - val_loss: 0.5713 - val_accuracy: 0.8299\n",
            "Epoch 35/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.5257 - accuracy: 0.8387 - val_loss: 0.5648 - val_accuracy: 0.8294\n",
            "Epoch 36/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.5124 - accuracy: 0.8431 - val_loss: 0.5339 - val_accuracy: 0.8417\n",
            "Epoch 37/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.4987 - accuracy: 0.8473 - val_loss: 0.5213 - val_accuracy: 0.8465\n",
            "Epoch 38/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.4873 - accuracy: 0.8508 - val_loss: 0.5117 - val_accuracy: 0.8493\n",
            "Epoch 39/100\n",
            "141/141 [==============================] - 4s 31ms/step - loss: 0.4748 - accuracy: 0.8550 - val_loss: 0.4965 - val_accuracy: 0.8496\n",
            "Epoch 40/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.4629 - accuracy: 0.8583 - val_loss: 0.4845 - val_accuracy: 0.8520\n",
            "Epoch 41/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.4510 - accuracy: 0.8615 - val_loss: 0.4830 - val_accuracy: 0.8537\n",
            "Epoch 42/100\n",
            "141/141 [==============================] - 5s 34ms/step - loss: 0.4398 - accuracy: 0.8645 - val_loss: 0.4433 - val_accuracy: 0.8689\n",
            "Epoch 43/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.4282 - accuracy: 0.8689 - val_loss: 0.4487 - val_accuracy: 0.8667\n",
            "Epoch 44/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.4184 - accuracy: 0.8718 - val_loss: 0.4250 - val_accuracy: 0.8721\n",
            "Epoch 45/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.4074 - accuracy: 0.8748 - val_loss: 0.4159 - val_accuracy: 0.8741\n",
            "Epoch 46/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.3978 - accuracy: 0.8781 - val_loss: 0.3986 - val_accuracy: 0.8815\n",
            "Epoch 47/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.3878 - accuracy: 0.8812 - val_loss: 0.3874 - val_accuracy: 0.8854\n",
            "Epoch 48/100\n",
            "141/141 [==============================] - 4s 31ms/step - loss: 0.3775 - accuracy: 0.8841 - val_loss: 0.3739 - val_accuracy: 0.8889\n",
            "Epoch 49/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.3687 - accuracy: 0.8865 - val_loss: 0.3709 - val_accuracy: 0.8901\n",
            "Epoch 50/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.3596 - accuracy: 0.8885 - val_loss: 0.3557 - val_accuracy: 0.8939\n",
            "Epoch 51/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.3497 - accuracy: 0.8927 - val_loss: 0.3422 - val_accuracy: 0.8979\n",
            "Epoch 52/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.3416 - accuracy: 0.8948 - val_loss: 0.3421 - val_accuracy: 0.8969\n",
            "Epoch 53/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.3332 - accuracy: 0.8970 - val_loss: 0.3217 - val_accuracy: 0.9040\n",
            "Epoch 54/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.3242 - accuracy: 0.9003 - val_loss: 0.3296 - val_accuracy: 0.9011\n",
            "Epoch 55/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.3160 - accuracy: 0.9028 - val_loss: 0.3170 - val_accuracy: 0.9041\n",
            "Epoch 56/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.3077 - accuracy: 0.9051 - val_loss: 0.3018 - val_accuracy: 0.9099\n",
            "Epoch 57/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.3000 - accuracy: 0.9080 - val_loss: 0.2936 - val_accuracy: 0.9124\n",
            "Epoch 58/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.2926 - accuracy: 0.9099 - val_loss: 0.2844 - val_accuracy: 0.9156\n",
            "Epoch 59/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.2846 - accuracy: 0.9122 - val_loss: 0.2785 - val_accuracy: 0.9181\n",
            "Epoch 60/100\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 0.2781 - accuracy: 0.9147 - val_loss: 0.2715 - val_accuracy: 0.9195\n",
            "Epoch 61/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.2697 - accuracy: 0.9173 - val_loss: 0.2572 - val_accuracy: 0.9233\n",
            "Epoch 62/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.2629 - accuracy: 0.9196 - val_loss: 0.2564 - val_accuracy: 0.9227\n",
            "Epoch 63/100\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 0.2566 - accuracy: 0.9216 - val_loss: 0.2541 - val_accuracy: 0.9238\n",
            "Epoch 64/100\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 0.2493 - accuracy: 0.9238 - val_loss: 0.2399 - val_accuracy: 0.9294\n",
            "Epoch 65/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.2421 - accuracy: 0.9261 - val_loss: 0.2244 - val_accuracy: 0.9336\n",
            "Epoch 66/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.2358 - accuracy: 0.9282 - val_loss: 0.2212 - val_accuracy: 0.9360\n",
            "Epoch 67/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.2302 - accuracy: 0.9294 - val_loss: 0.2126 - val_accuracy: 0.9392\n",
            "Epoch 68/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.2242 - accuracy: 0.9319 - val_loss: 0.2094 - val_accuracy: 0.9390\n",
            "Epoch 69/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.2173 - accuracy: 0.9337 - val_loss: 0.2018 - val_accuracy: 0.9422\n",
            "Epoch 70/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.2108 - accuracy: 0.9356 - val_loss: 0.1988 - val_accuracy: 0.9427\n",
            "Epoch 71/100\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 0.2052 - accuracy: 0.9378 - val_loss: 0.1871 - val_accuracy: 0.9463\n",
            "Epoch 72/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1999 - accuracy: 0.9392 - val_loss: 0.1880 - val_accuracy: 0.9452\n",
            "Epoch 73/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1948 - accuracy: 0.9414 - val_loss: 0.1733 - val_accuracy: 0.9511\n",
            "Epoch 74/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.1884 - accuracy: 0.9429 - val_loss: 0.1833 - val_accuracy: 0.9452\n",
            "Epoch 75/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1834 - accuracy: 0.9444 - val_loss: 0.1710 - val_accuracy: 0.9504\n",
            "Epoch 76/100\n",
            "141/141 [==============================] - 4s 32ms/step - loss: 0.1781 - accuracy: 0.9466 - val_loss: 0.1594 - val_accuracy: 0.9535\n",
            "Epoch 77/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1736 - accuracy: 0.9474 - val_loss: 0.1618 - val_accuracy: 0.9530\n",
            "Epoch 78/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1678 - accuracy: 0.9497 - val_loss: 0.1553 - val_accuracy: 0.9560\n",
            "Epoch 79/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1637 - accuracy: 0.9505 - val_loss: 0.1549 - val_accuracy: 0.9559\n",
            "Epoch 80/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1593 - accuracy: 0.9518 - val_loss: 0.1417 - val_accuracy: 0.9603\n",
            "Epoch 81/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1551 - accuracy: 0.9533 - val_loss: 0.1448 - val_accuracy: 0.9589\n",
            "Epoch 82/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1513 - accuracy: 0.9546 - val_loss: 0.1357 - val_accuracy: 0.9614\n",
            "Epoch 83/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1447 - accuracy: 0.9566 - val_loss: 0.1408 - val_accuracy: 0.9601\n",
            "Epoch 84/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1424 - accuracy: 0.9575 - val_loss: 0.1332 - val_accuracy: 0.9621\n",
            "Epoch 85/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1383 - accuracy: 0.9592 - val_loss: 0.1288 - val_accuracy: 0.9643\n",
            "Epoch 86/100\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 0.1353 - accuracy: 0.9596 - val_loss: 0.1172 - val_accuracy: 0.9673\n",
            "Epoch 87/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1317 - accuracy: 0.9608 - val_loss: 0.1140 - val_accuracy: 0.9688\n",
            "Epoch 88/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1278 - accuracy: 0.9620 - val_loss: 0.1104 - val_accuracy: 0.9701\n",
            "Epoch 89/100\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 0.1242 - accuracy: 0.9637 - val_loss: 0.1136 - val_accuracy: 0.9677\n",
            "Epoch 90/100\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 0.1214 - accuracy: 0.9642 - val_loss: 0.1174 - val_accuracy: 0.9672\n",
            "Epoch 91/100\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 0.1184 - accuracy: 0.9650 - val_loss: 0.1044 - val_accuracy: 0.9715\n",
            "Epoch 92/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1152 - accuracy: 0.9657 - val_loss: 0.0979 - val_accuracy: 0.9732\n",
            "Epoch 93/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1127 - accuracy: 0.9658 - val_loss: 0.0975 - val_accuracy: 0.9737\n",
            "Epoch 94/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1095 - accuracy: 0.9678 - val_loss: 0.0967 - val_accuracy: 0.9731\n",
            "Epoch 95/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1070 - accuracy: 0.9683 - val_loss: 0.0948 - val_accuracy: 0.9739\n",
            "Epoch 96/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1048 - accuracy: 0.9695 - val_loss: 0.0954 - val_accuracy: 0.9747\n",
            "Epoch 97/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.1021 - accuracy: 0.9701 - val_loss: 0.0977 - val_accuracy: 0.9726\n",
            "Epoch 98/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.0989 - accuracy: 0.9710 - val_loss: 0.0871 - val_accuracy: 0.9767\n",
            "Epoch 99/100\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 0.0970 - accuracy: 0.9714 - val_loss: 0.0834 - val_accuracy: 0.9782\n",
            "Epoch 100/100\n",
            "141/141 [==============================] - 5s 32ms/step - loss: 0.0952 - accuracy: 0.9723 - val_loss: 0.0810 - val_accuracy: 0.9787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/DeepLearning/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/DeepLearning/model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6d23b3bb10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6d200547d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ9nT-_AIQGd"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.models.load_model(base_path + \"model\")\n",
        "# model.compile(\n",
        "#     optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "# )"
      ],
      "metadata": {
        "id": "teiWUYSayFpD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVyJd6wIIIqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1455a848-ccdf-4512-951a-58e66cb91015"
      },
      "source": [
        "model.evaluate([encoder_input_data_test, decoder_input_data_test], decoder_target_data_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 15ms/step - loss: 2.2626 - accuracy: 0.6428\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.2625625133514404, 0.6428235173225403]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abYc26H36Dua"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZIYazoQpM-8"
      },
      "source": [
        "# Define sampling models\n",
        "# Restore the model and construct the encoder and decoder.\n",
        "encoder_inputs = model.input[0]  # input_1\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]  # input_2\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_scores = list()\n",
        "dim_list = list()"
      ],
      "metadata": {
        "id": "YiYfl3aqkVEj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2O3IcN7fwJC"
      },
      "source": [
        "n = len(input_text_test)\n",
        "sentence_scores = list()\n",
        "sentence_1gram_scores = list()\n",
        "decoded_sentences = list(list())\n",
        "target_sentences = list(list(list()))\n",
        "text=\"\"\"\"\"\"\n",
        "\n",
        "with open(base_path+\"decode.txt\", \"w\") as df: \n",
        "\n",
        "    for seq_index in range(n):\n",
        "        # Take one sequence (part of the training set)\n",
        "        # for trying out decoding.\n",
        "        input_seq = encoder_input_data_test[seq_index : seq_index + 1]\n",
        "        decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "        indices = duplicates(input_text, input_text_test[seq_index])\n",
        "\n",
        "        # sentence score\n",
        "        sentence_scores.append(sentence_bleu([[target_text[i] for i in indices]], [decoded_sentence]))\n",
        "        sentence_1gram_scores.append(sentence_bleu([[target_text[i] for i in indices]], [decoded_sentence], weights=(1, 0, 0, 0)))\n",
        "\n",
        "        #corpus score\n",
        "        target_sentences.append([[target_text[i] for i in indices]])\n",
        "        decoded_sentences.append([decoded_sentence])\n",
        "\n",
        "        text+=\"-\"\n",
        "        text+=\"Input sentence:{}\\n\".format(input_text_test[seq_index])\n",
        "        text+=\"Target sentence:\\n\"\n",
        "\n",
        "        for i in indices:\n",
        "            text+=target_text[i]\n",
        "        \n",
        "        text+=\"Decoded sentence:{}\\n\".format(decoded_sentence) \n",
        "\n",
        "    print(text, file=df)\n",
        "    df.close()\n",
        "\n",
        "corpus_scores.append(corpus_bleu(target_sentences, decoded_sentences))\n",
        "dim_list.append(latent_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph Plot"
      ],
      "metadata": {
        "id": "EqkTccHNQ3Pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# x axis values\n",
        "x = [i for i in range(len(sentence_scores))]\n",
        "\n",
        "# corresponding y axis values\n",
        "y = sentence_scores\n",
        " \n",
        "# plotting the points\n",
        "plt.plot(x, y)\n",
        " \n",
        "# naming the x axis\n",
        "plt.xlabel('Sentence Indices')\n",
        "# naming the y axis\n",
        "plt.ylabel('Sentence BLEU Score')\n",
        " \n",
        "# giving a title to my graph\n",
        "plt.title('Sentence BLEU Scores for Test Data')\n",
        " \n",
        "# function to show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RE2z2zrlQ4xY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e08ee70e-be3f-46d0-8ec5-455fe8012c36"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x axis values\n",
        "x = [i for i in range(len(sentence_1gram_scores))]\n",
        "\n",
        "# corresponding y axis values\n",
        "y = sentence_1gram_scores\n",
        " \n",
        "# plotting the points\n",
        "plt.plot(x, y)\n",
        " \n",
        "# naming the x axis\n",
        "plt.xlabel('Sentence Indices')\n",
        "# naming the y axis\n",
        "plt.ylabel('Sentence 1-gram BLEU Score')\n",
        " \n",
        "# giving a title to my graph\n",
        "plt.title('Sentence 1-gram BLEU Scores for Test Data')\n",
        " \n",
        "# function to show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mmoqpv5mkNtp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b9236159-02b5-4b96-ae71-7df2f4cc495a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}